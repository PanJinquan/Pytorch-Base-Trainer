7767517
29 28
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,48,256)f32
nn.Conv2d                convbn2d_0               1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(5,5) out_channels=24 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,3,5,5)f32 $input=0 #0=(1,3,48,256)f32 #1=(1,24,44,252)f32
nn.ReLU                  feature.2                1 1 1 2 #1=(1,24,44,252)f32 #2=(1,24,44,252)f32
nn.Conv2d                convbn2d_1               1 1 2 3 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,24,3,3)f32 $input=2 #2=(1,24,44,252)f32 #3=(1,24,44,252)f32
nn.ReLU                  feature.5                1 1 3 4 #3=(1,24,44,252)f32 #4=(1,24,44,252)f32
nn.Conv2d                convbn2d_2               1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,24,3,3)f32 $input=4 #4=(1,24,44,252)f32 #5=(1,48,44,252)f32
nn.ReLU                  feature.8                1 1 5 6 #5=(1,48,44,252)f32 #6=(1,48,44,252)f32
nn.Conv2d                convbn2d_3               1 1 6 7 bias=True dilation=(1,1) groups=1 in_channels=48 kernel_size=(3,3) out_channels=48 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(48)f32 @weight=(48,48,3,3)f32 $input=6 #6=(1,48,44,252)f32 #7=(1,48,44,252)f32
nn.ReLU                  feature.11               1 1 7 8 #7=(1,48,44,252)f32 #8=(1,48,44,252)f32
nn.MaxPool2d             feature.12               1 1 8 9 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(1,1) return_indices=False stride=(2,2) #8=(1,48,44,252)f32 #9=(1,48,22,126)f32
nn.Conv2d                convbn2d_4               1 1 9 10 bias=True dilation=(1,1) groups=1 in_channels=48 kernel_size=(3,3) out_channels=96 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,48,3,3)f32 $input=9 #9=(1,48,22,126)f32 #10=(1,96,22,126)f32
nn.ReLU                  feature.15               1 1 10 11 #10=(1,96,22,126)f32 #11=(1,96,22,126)f32
nn.Conv2d                convbn2d_5               1 1 11 12 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(3,3) out_channels=96 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,96,3,3)f32 $input=11 #11=(1,96,22,126)f32 #12=(1,96,22,126)f32
nn.ReLU                  feature.18               1 1 12 13 #12=(1,96,22,126)f32 #13=(1,96,22,126)f32
nn.MaxPool2d             feature.19               1 1 13 14 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(1,1) return_indices=False stride=(2,2) #13=(1,96,22,126)f32 #14=(1,96,11,63)f32
nn.Conv2d                convbn2d_6               1 1 14 15 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,96,3,3)f32 $input=14 #14=(1,96,11,63)f32 #15=(1,128,11,63)f32
nn.ReLU                  feature.22               1 1 15 16 #15=(1,128,11,63)f32 #16=(1,128,11,63)f32
nn.Conv2d                convbn2d_7               1 1 16 17 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,3,3)f32 $input=16 #16=(1,128,11,63)f32 #17=(1,128,11,63)f32
nn.ReLU                  feature.25               1 1 17 18 #17=(1,128,11,63)f32 #18=(1,128,11,63)f32
nn.MaxPool2d             feature.26               1 1 18 19 ceil_mode=False dilation=(1,1) kernel_size=(3,3) padding=(0,0) return_indices=False stride=(2,2) #18=(1,128,11,63)f32 #19=(1,128,5,31)f32
nn.Conv2d                convbn2d_8               1 1 19 20 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=192 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,128,3,3)f32 $input=19 #19=(1,128,5,31)f32 #20=(1,192,5,31)f32
nn.ReLU                  feature.29               1 1 20 21 #20=(1,192,5,31)f32 #21=(1,192,5,31)f32
nn.Conv2d                convbn2d_9               1 1 21 22 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(3,3) out_channels=192 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,192,3,3)f32 $input=21 #21=(1,192,5,31)f32 #22=(1,192,5,31)f32
nn.ReLU                  feature.32               1 1 22 23 #22=(1,192,5,31)f32 #23=(1,192,5,31)f32
nn.MaxPool2d             loc                      1 1 23 24 ceil_mode=False dilation=(1,1) kernel_size=(5,2) padding=(0,1) return_indices=False stride=(1,1) #23=(1,192,5,31)f32 #24=(1,192,1,32)f32
nn.Conv2d                newCnn                   1 1 24 25 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=23 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(23)f32 @weight=(23,192,1,1)f32 #24=(1,192,1,32)f32 #25=(1,23,1,32)f32
torch.squeeze            torch.squeeze_0          1 1 25 26 dim=2 $input=25 #25=(1,23,1,32)f32 #26=(1,23,32)f32
torch.transpose          torch.transpose_1        1 1 26 27 dim0=2 dim1=1 $input=26 #26=(1,23,32)f32 #27=(1,32,23)f32
pnnx.Output              pnnx_output_0            1 0 27 #27=(1,32,23)f32
